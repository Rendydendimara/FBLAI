const fs = require("fs");
const { parse } = require("csv-parse");
const axios = require('axios');
require('dotenv').config()
const { stringify } = require("csv-stringify");
const AdmZip = require("adm-zip");
const xlsx = require('node-xlsx').default;
const { getSheetsNameByCallNumber } = require('../utils')

const FOLDER_RESULT = "results"
const COLUMNS_CSV = [
  "title",
  "gmdId",
  "edition",
  "isbnIssn",
  "penerbit",
  "tahunTerbit",
  "collation",
  "seriesTitle",
  "callnumber",
  "language",
  "publish_place_id",
  "classification",
  "description",
  "image",
  "NO DATA",
  "authors",
  "subject",
];
const PORT = process.env.PORT;
const BACKEND_URL = process.env.BACKEND_URL;
const NODE_ENV = process.env.NODE_ENV;

const PostFileUseCase = async (
  req,
  res,
  next
) => {
  try {
    console.time('running fetch');
    // console.log(req.file, req.body)
    const CALL_NUMBER = req.body.subject
    const filename = req.file.filename;
    const pathZip = `${FOLDER_RESULT}/${filename}/${filename}.zip`
    console.log('pathZip', pathZip)
    prepare(filename);
    const resultReadCVS = await readFile(`./${req.file.path}`, CALL_NUMBER);
    console.log(`total result read data in ${filename}: `, resultReadCVS.length)
    const resultFetchBooks = await fetchBooks(resultReadCVS.slice(2, 10), filename)
    await delay(2000);
    await createCSVImport(resultFetchBooks.resultDataSuccess, filename, "found", CALL_NUMBER)
    await delay(2000);
    await createCSVImport(resultFetchBooks.resultDataError, filename, "notFound", CALL_NUMBER)
    await delay(2000);
    await createZipArchive(pathZip, `${FOLDER_RESULT}/${filename}`)
    console.timeEnd('running fetch');

    const filePath =
      NODE_ENV === 'development'
        ? `${req.protocol}://${req.hostname}:${PORT}/${pathZip}`
        : `${BACKEND_URL}/${pathZip}`;

    return res.send({
      message: ' Success',
      data: filePath,
      error: false
    })

  } catch (e) {
    next(e);
  }
};

module.exports = { PostFileUseCase };



const readFile = (path, callNumber) => new Promise((resolve, reject) => {
  const dataReader = [];
  const workSheetsFromFile = xlsx.parse(path);
  const listSheetsName = getSheetsNameByCallNumber(Number(callNumber))
  for (i = 0; i < listSheetsName.length; i++) {
    let dataEnsiklopedi = workSheetsFromFile.filter((dt) => dt.name === listSheetsName[i])[0]
    dataEnsiklopedi = dataEnsiklopedi ? dataEnsiklopedi : { data: [] }
    dataEnsiklopedi.data.forEach((dt) => {
      if (dt[3] !== '' && dt[3] !== null && dt[3] !== undefined && dt[5] !== '' && dt[5] !== null && dt[5] !== undefined) {
        const isbn = getFixISBN(dt[1]);
        dataReader.push({
          isbn: isbn,
          judulBuku: dt[3],
          defaultIsbn: dt[1],
          defaultData: dt
        })
      }
    })
  }
  resolve(dataReader)


  // fs.createReadStream(path)
  //   .pipe(parse({ delimiter: ",", from_line: 2 }))
  //   .on("data", async function (row) {
  //     if (row[3] !== 'Judul Buku' && row[3] !== '') {
  //       // console.log('row', row)
  //       const isbn = getFixISBN(row[1]);
  //       dataReader.push({
  //         isbn: isbn,
  //         judulBuku: row[3],
  //         defaultIsbn: row[1],
  //         defaultData: row
  //       })
  //     }
  //   })
  //   .on("end", function () {
  //     resolve(dataReader);
  //   })
  //   .on("error", function (error) {
  //     reject(error);
  //   });
});

const prepare = (folderName) => {
  // create folder
  if (!fs.existsSync(`${FOLDER_RESULT}/${folderName}`)) {
    fs.mkdirSync(`${FOLDER_RESULT}/${folderName}`, { recursive: true });
  }
}

const getFixISBN = (isbn) => {
  let fixIsbn = isbn ? isbn : '';
  if (typeof (fixIsbn) !== 'string') {
    fixIsbn = ''
  }
  // remove spesial characters
  fixIsbn = fixIsbn.replace(/[^a-zA-Z0-9 ]/g, "");
  // remove WORD contain: ISSN
  fixIsbn = fixIsbn.replace(/ISSN/g, "");
  // remove space, tabs
  fixIsbn = fixIsbn.replace(/ /g, "");

  return fixIsbn;
}

const fetchBooks = (data, folderName) => new Promise(async (resolve, reject) => {
  const resultDataSuccess = []
  const resultDataError = []
  for (i = 0; i < data.length; i++) {
    if (data[i].isbn) {
      console.log(`find isbn: ${data[i].isbn}`)
      try {
        const res = await axios(`https://www.googleapis.com/books/v1/volumes?q=isbn:${data[i].isbn}`);
        if (res.status === 200 && res.data.totalItems > 0) {
          resultDataSuccess.push({ isbn: data[i].isbn, defaultIsbn: data[i].defaultIsbn, dataFetch: res.data, defaultData: data[i].defaultData });
          if (res.data.totalItems > 0 && res.data.items[0].volumeInfo.imageLinks) {
            const imageUrl = res.data.items[0].volumeInfo.imageLinks.smallThumbnail || res.data.items[0].volumeInfo.imageLinks.thumbnail || undefined;
            if (imageUrl) {
              await downloadImage(imageUrl, `${FOLDER_RESULT}/${folderName}/${data[i].defaultIsbn}.jpeg`);
            }
          }
        } else {
          resultDataError.push({ isbn: data[i].isbn, defaultIsbn: data[i].defaultIsbn, dataFetch: null, defaultData: data[i].defaultData });
        }
      } catch (err) {
        console.log(err)
      }
    }
  }
  resolve({
    resultDataSuccess,
    resultDataError
  });
});

const downloadImage = (url, filename) => new Promise(async (resolve, reject) => {
  const response = await axios.get(url, { responseType: 'arraybuffer' });
  fs.writeFile(filename, response.data, (err) => {
    if (err) throw resolve(err);
    resolve(true)
  });
})

const createCSVImport = (data, filename, type, callNumber) => new Promise(async (resolve, reject) => {
  if (type === "notFound") {
    const filenameResult = `./${FOLDER_RESULT}/${filename}/${filename}-result-not-found.csv`;
    const writableStream = fs.createWriteStream(filenameResult);
    const stringifier = stringify({ header: true, columns: COLUMNS_CSV });
    for (let j = 0; j < data.length; j++) {
      let authorsFix = ""
      const dataAuthors = [data[j].defaultData[12].trim()]

      dataAuthors.forEach((dt) => {
        authorsFix += `<${dt}>`;
      })

      const result = [
        data[j].defaultData[3].trim(), //title
        "Text", //gmdId
        null, // edition
        data[j].isbn, // isbnIssn
        data[j].defaultData[11].trim(), // publisherName
        data[j].defaultData[14], // publishYear
        "-", // collation
        null, // seriesTitle
        callNumber, // callNumber
        data[j].defaultData[8], // languageId
        data[j].defaultData[6], // publishPlaceId
        data[j].defaultData[2].trim(), // classification
        "-", //notes
        "nof-found.png", // image
        "-", // NO DATA
        dataAuthors, // authors
        `<${data[j].defaultData[5].trim()}>`, // subjects
      ];
      // arrayDataToDump.push(data)
      console.log('result', result)
      stringifier.write(result);
    }
    await stringifier.pipe(writableStream);
    resolve(true)
  } else {
    const filenameResult = `./${FOLDER_RESULT}/${filename}/${filename}-result-found.csv`;
    const writableStream = fs.createWriteStream(filenameResult);
    const stringifier = stringify({ header: true, columns: COLUMNS_CSV });
    for (let j = 0; j < data.length; j++) {
      const fetchData = data[j].dataFetch.items[0]
      const originalData = data[j].defaultData
      let authorsFix = ""

      const dataAuthors = fetchData.volumeInfo.authors ? fetchData.volumeInfo.authors : [data[j].defaultData[12].trim()]

      dataAuthors.forEach((dt) => {
        authorsFix += `<${dt}>`;
      })

      const result = [
        fetchData.volumeInfo.title, // title
        "Text", // gmdId
        null, // edition
        data[j].isbn, // isbnIssn
        fetchData.volumeInfo.publisher, // publisherName
        fetchData.volumeInfo.publishedDate, // publishYear
        `${data[j].defaultData[2].trim()} - ${data[j].defaultData[15]}`, // collation
        null, // seriesTitle
        callNumber, // callNumber
        data[j].defaultData[8], // languageId
        data[j].defaultData[6], // publishPlaceId
        data[j].defaultData[2].trim(), // classification
        fetchData.volumeInfo.description, //notes
        `${data[j].defaultIsbn}.jpeg`, // image
        "-", // NO DATA
        authorsFix, // authors
        `<${data[j].defaultData[5].trim()}>`, // subjects        
      ]
      stringifier.write(result);
    }
    await stringifier.pipe(writableStream);
    resolve(true)
  }
});

const createZipArchive = (filename, folderSource) => new Promise(async (resolve, reject) => {
  try {
    const zip = new AdmZip();
    zip.addLocalFolder(folderSource);
    zip.writeZip(filename);
    resolve(true)
  } catch (e) {
    console.log(`Something went wrong. ${e}`);
    reject(e)
  }
});

const delay = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

